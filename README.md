# Hand Sign Language Recognition for Deaf and Dumb

Welcome to our Hand Sign Language Recognition project repository! This project focuses on real-time sign language recognition using machine learning and mobile technologies.

![Banner](./path_to_banner_image)

## Overview

Our project leverages machine learning and mobile development to create a real-time sign language recognition application. By combining image preprocessing, model training, and mobile integration, we enable communication through sign language for the deaf and mute community.

## Key Features

- Real-time recognition of ASL gestures
- High accuracy and low latency
- User-friendly interface designed for accessibility

## Technology Stack

### Front-end (Mobile App)

- **Language:** Kotlin
- **Development Environment:** Android Studio

### Back-end

- **Cloud Services:** Firebase (Authentication, Cloud Firestore)

### Machine Learning

- **Framework:** MediaPipe

## Team Members

Meet the team behind this project:


| Name              | Email                       | GitHub                  						| LinkedIn                                     						 |
| ----------------- | --------------------------- | ---------------------------------------------	| ----------------------------------------------------------------   |
| Sameer Shrikhande | sameershrikhande6@gmail.com | [GitHub](https://github.com/sameershrikhande)   | [LinkedIn](https://www.linkedin.com/in/sameershrikhande/) 		 |
| Hardik Pingale    | hardikpingale7@gmail.com    | [GitHub](https://github.com/Hardik-Pingale)     | [LinkedIn](https://www.linkedin.com/in/hardikpingale/) 			 |
| Mohammad Asif     | msasifm4@gmail.com          | [GitHub](https://github.com/msasifm4)           | [LinkedIn](https://www.linkedin.com/in/mohammed-asif-shaikh-/)	 |
| Abhishek Joshi    | abhinj29@gmail.com          | [GitHub](https://github.com/Abhi-29-jo)         | [LinkedIn](https://www.linkedin.com/in/abhishek-joshi-3676401a6/)	 |



## Project Details

- **Project Report:** [Report.pdf](drivelink)
- **Published Paper:** [Paper.pdf](drivelink)
- **Dataset:** [Dataset](https://drive.google.com/drive/folders/1M2SdYYNskVWP5gPj8kpDTnFuvKpk_pQc?usp=sharing)
- **Gesture Recognition Documentation:** [MediaPipe](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer)
- **Model Training File:** `model_training.ipynb` (located in the root folder)

## Screenshots

Here are some snapshots of our application:

![Screenshot 1](./screenshots/screenshot1.png)
![Screenshot 2](./screenshots/screenshot2.png)
![Screenshot 3](./screenshots/screenshot3.png)

## Support

For any questions or support, feel free to reach out:

- **Email:** email@example.com
- **LinkedIn:** [Name](linkedin_profile_link)
